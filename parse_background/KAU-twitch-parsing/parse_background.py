#!/usr/bin/python3

import pandas as pd
import os
from multiprocessing import Pool
import timeit
import tqdm
import argparse

ap = argparse.ArgumentParser()
ap.add_argument("-w"     , required = False, default = 10 , type = int, help = "number of workers (multiprocessing)")
args = vars(ap.parse_args())

'''
TODO: progressbar
'''

def main():
    '''
    To run parse_background from the terminal
    '''
    parse_background(workers= args['w'])
    return

def parse_background(dir_input = "twitch/usable_captures_h5/", dir_output  = "twitch/parsed_captures/", workers = 10):
    '''
    Parse background data generated by rds-collect

    Assumption about the input:
    * the files has been converted to hdf5 files (run log_2_h5.py)
    * that the unusable files have been removed
    * that the captured data starts its captures from the time 0
    * The capture names are not sorted in any particular order

    Args:
        dir_input  - Optional : Path to the capture files that should be parsed (str)
        dir_output - Optional : Path to the parsed capture files                (str)
        workers    - optional : number of workers (multiprocessing)             (int)
    '''

    print("Start parsing (make take some time)")

    # clean old results if their is any
    if os.path.exists(dir_output):
        shutil.rmtree(dir_output)
    os.mkdir(dir_output)

    # the capture files that will be parsed
    # sort after file name, which do not follow any particular pattern (but makes it replicable)
    input_files = os.listdir(dir_input)
    input_files.sort()
    
    # one element for each file to parse
    input = []
    for curr_file in input_files:
        input.append((curr_file, dir_input, dir_output))

    start_time = timeit.default_timer()

    p = Pool(workers)
    p.starmap(parse_file, input)

    end_time = timeit.default_timer()
    run_time_min = (end_time - start_time)/60
    print(f"runtime for parsing (min): {run_time_min:.2f}")
    return


def parse_file(file, dir_input = "twitch/usable_captures_h5/", dir_output  = "twitch/parsed_captures/"):
    '''
    Parse the provided file and store teh result

    Args:
        file       - Required : the file name of the capture file to parse                                    (str)
        dir_input  - Optional : Path to the capture files that should be parsed                               (str)
        dir_output - Optional : Path to the parsed capture files                                              (str)
    '''
    # 1000000000 ns = 1 sec
    NANO_SEC_PER_SEC = 1000000000
    # How much of the header to remove (to fit the noise with the web traffic)
    HEADER = 40
    # for storing the result as h5
    KEY = "df"
    TIME_INDEX            = 1
    SENDER_RECEIVER_INDEX = 2
    SIZE_INDEX            = 3
    DF_COLUMNS = ['time', 'direction', 'size']

    # Ip address for the host, do not need to be correct, but MUST start with "10." 
    ipHost = '10.88.0.9'
    # should start at 0 for each file
    prev_time_float_sec = 0
    # to store the parsed file
    df_parsed = pd.DataFrame(columns = DF_COLUMNS)
    # Dictionary to append the results for each row for a file
    dictionary_parsed = {
        'time'     : [],
        'direction': [],
        'size'     : []
    }

    filename = os.fsdecode(file)

    # get the data from the current file 
    # (sort them to make sure that they are in the right order)
    path        = dir_input + filename
    df_unsorted = pd.read_hdf(path, key = KEY)
    df          = df_unsorted.sort_values(by = 'time')

    for row in df.itertuples():
        # flag to check if the packet is broken, so it can be skipped
        broken = False

        # convert from absolute timestamp in sec, to relative timestamp in NS
        if not row[TIME_INDEX]:
            broken = True
            continue
        else:
            # get the duration (NS int) between this packet, and the one before it
            parsed_time_float_sec = row[TIME_INDEX] - prev_time_float_sec
            parsed_time_int_ns    = round(parsed_time_float_sec * NANO_SEC_PER_SEC)

            # if the time is is broken 
            if parsed_time_int_ns < 0:
                broken = True
                continue
            # if the time have been rounded to 0
            elif parsed_time_int_ns == 0:
                parsed_time_int_ns = 1

        sender_receiver = str(row[SENDER_RECEIVER_INDEX]).split(",")
        # if no or only one IP address, skip this packet
        if len(sender_receiver) < 2:
            broken = True
            continue
        else:
            sender   = sender_receiver[0]
            receiver = sender_receiver[1]
            # get direction
            if sender == "":
                broken = True
                continue
            elif sender == ipHost:
                parsed_direction = "sb"
            elif receiver == ipHost:
                parsed_direction = "rb"
            # have the wrong IP address for the host, get the correct one
            else:
                sender_start_ip = sender.split('.')
                if sender_start_ip[0] == '10':
                    ipHost = sender_start_ip[0]
                    parsed_direction = "sb"
                else:
                    ipHost = sender_start_ip[1]
                    parsed_direction = "rb"

        # get size
        try:
            parsed_size = int(row[SIZE_INDEX]) - HEADER
            if parsed_size <= 0:
                broken = True
                continue
        except:
            broken = True
            continue

        if not broken:
            dictionary_parsed['time'].append(parsed_time_int_ns)
            dictionary_parsed['direction'].append(parsed_direction)
            dictionary_parsed['size'].append(parsed_size)

            # update time for the packet before (in sec as float)
            prev_time_float_sec = row[TIME_INDEX]

    # have parsed the whole file, store the result
    df_parsed = pd.DataFrame(dictionary_parsed)
    df_file_name = dir_output + filename.rsplit('.', 1)[0] + '.h5'
    df_parsed.to_hdf(df_file_name, mode = "w", key = KEY) 

    return


# run main 
if __name__=="__main__":
    main()